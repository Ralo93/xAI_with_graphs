import numpy as np
import torch
from torch_geometric.nn import GCNConv
from torch.nn import Linear, Dropout, ReLU
from torch_geometric.datasets import Planetoid
from torch_geometric.explain import Explainer, GNNExplainer
import networkx as nx
import matplotlib.pyplot as plt
from pyvis.network import Network

import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GATConv

# GAT model
class GAT(torch.nn.Module):
    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int,
                 num_heads: int = 4, dropout: float = 0.3, edge_dim: int = None):
        super().__init__()

        self.dropout = Dropout(dropout)

        # Calculate output dimensions
        self.gat1_out_channels = hidden_channels * num_heads
        self.gat2_out_channels = hidden_channels * num_heads

        # Replace BatchNorm with LayerNorm
        self.norm1 = nn.LayerNorm(self.gat1_out_channels)
        self.norm2 = nn.LayerNorm(self.gat2_out_channels)

        # Input projection for skip connection
        self.proj_skip = nn.Linear(in_channels, self.gat2_out_channels)

        self.gat1 = GATConv(
            in_channels=in_channels,
            out_channels=hidden_channels,
            heads=num_heads,
            concat=True,
            dropout=dropout,
            edge_dim=edge_dim,
            add_self_loops=False  ## The underlaying model might have self loops!!
        )

        self.gat2 = GATConv(
            in_channels=hidden_channels * num_heads,
            out_channels=hidden_channels,
            heads=num_heads,
            concat=True,
            dropout=dropout,
            add_self_loops=False
        )

        self.gat3 = GATConv(
            in_channels=hidden_channels * num_heads,
            out_channels=out_channels,# // num_heads,
            heads=num_heads,
            concat=False,
            dropout=dropout,
            add_self_loops=False
        )

    def forward(self, x, edge_index, return_attention=False):
        """Debugging: return logits and attention weights."""
        # Save input for skip connection
        x_skip = x

        # GAT layer 1
        x, alpha1 = self.gat1(x, edge_index, return_attention_weights=True)
        x = F.elu(x)
        x = self.norm1(x)
        x = self.dropout(x)

        # GAT layer 2
        x_skip = self.proj_skip(x_skip)  # Align dimensions for skip connection
        x = x + x_skip  # Add skip connection
        x, alpha2 = self.gat2(x, edge_index, return_attention_weights=True)
        x = F.elu(x)
        x = self.norm2(x)
        x = self.dropout(x)

        # GAT layer 3
        x, alpha3 = self.gat3(x, edge_index, return_attention_weights=True)

        if return_attention:
            return x, [alpha1, alpha2, alpha3]
        return x
    


# Load dataset
dataset = Planetoid(root='data/Planetoid', name='Cora')
data = dataset[0]

# Train the GAT

# Define model, loss function, and optimizer
c_in = dataset.num_features
c_out = dataset.num_classes
gat_model = GAT(in_channels=c_in, hidden_channels=16, out_channels=c_out)
loss_function = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(gat_model.parameters(), lr=0.01, weight_decay=5e-4)

def train():
    gat_model.train()
    optimizer.zero_grad()
    out = gat_model(data.x, data.edge_index)  # Include attention outputs
    loss = loss_function(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()
    return loss.item()

def test(mask):
    gat_model.eval()
    with torch.no_grad():  # Disable gradient computation
        out = gat_model(data.x, data.edge_index)
        pred = out.argmax(dim=1)
        correct = (pred[mask] == data.y[mask]).sum().item()
        total = mask.sum().item()
        return correct / total

for epoch in range(1, 201):
    train_loss = train()
    train_acc = test(data.train_mask)
    val_acc = test(data.val_mask)
    test_acc = test(data.test_mask)
    print(
        f"Epoch: {epoch:03d}, Loss: {train_loss:.4f}, "
        f"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}"
    )

# Initialize the GNNExplainer and Explainer
explainer = Explainer(
    model=gat_model, 
    algorithm=GNNExplainer(epochs=200), 
    explanation_type='model',
    node_mask_type='attributes',
    edge_mask_type='object',
    model_config=dict(
        mode='multiclass_classification', 
        task_level='node', 
        return_type='log_probs'
    )
)

# Choose a node to explain (e.g., node index 10)
node_idx = 10

# Generate the explanation for the node (node explanation)
explanation = explainer(data.x, data.edge_index, index=node_idx)

# Explanation will include the masked features and edge attributes
node_feat_mask, edge_mask = explanation.node_mask, explanation.edge_mask


# Retrieve logits and attention weights
_, attention_weights = gat_model(data.x, data.edge_index, return_attention=True)


# Define the function to visualize the subgraph with PyVis
def visualize_subgraph_with_pyvis(node_idx, edge_index, node_mask, edge_mask):
    net = Network(notebook=True)

    # Get the nodes and edges based on the explanation
    subgraph_nodes = torch.nonzero(node_mask > 0, as_tuple=True)[0].cpu().numpy()
    subgraph_edges = torch.nonzero(edge_mask > 0, as_tuple=True)[0].cpu().numpy()

    # Add the nodes to PyVis network (convert node IDs to int)
    for i in subgraph_nodes:
        net.add_node(int(i), label=f"Node {int(i)}")  # Convert node ID to int

    # Add edges with edge weights (from attention mask) to PyVis network
    for idx in subgraph_edges:
        src, dst = edge_index[:, idx].cpu().numpy()
        weight = edge_mask[idx].item()  # Attention weight
        net.add_edge(int(src), int(dst), value=weight, title=f"Attention: {weight:.4f}")  # Convert indices to int

    # Visualize the network in Jupyter or save it to an HTML file
    net.show("gat_attention_subgraph.html")

# Assuming the explainer is already created and you've called `explain_node` method
# Call the function to visualize the subgraph
visualize_subgraph_with_pyvis(node_idx, data.edge_index, node_feat_mask, edge_mask)